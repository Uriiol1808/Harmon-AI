{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal project to improve my tensorflow/keras knowledge, while learning about audio extraction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Dataset Download](#2.-Dataset-Download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Audio feature extraction\n",
    "- Mel Frequency Cepstral Coefficients (MFCC)\n",
    "- Mel Spectrogram\n",
    "- Chroma Vector\n",
    "- Tonal Centroid Features (Tonnetz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Frequency Cepstral Coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs (Mel-Frequency Cepstral Coefficients) of an audio signal are small set of features which describe the overall shape of the spectral envelope. Frequently used for voice regonition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(path):\n",
    "    y, sr = librosa.load(path, offset=0, duration=30)\n",
    "    mfcc = np.array(librosa.feature.mfcc(y=y, sr=sr))\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mel spectrogram is a spectrogram where the frequencies are converted to the mel scale. Applies a frequency-domain filter bank to audio signal that are windowed in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_spectrogram(path):\n",
    "    y, sr = librosa.load(path, offset=0, duration=30)\n",
    "    mel_spectogram = np.array(librosa.feature.melspectrogram(y=y, sr=sr))\n",
    "    return mel_spectogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma-based features, also referred to as \"pitch class profiles\", represents the tonal content of a musical audio signal in a condensed form. Useful for chord recognition or harmonic similarity estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_vector(path):\n",
    "    y, sr = librosa.load(path)\n",
    "    chroma_vector = np.array(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    return chroma_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tonal Centroid Features (Tonnetz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tonnetz (German for \"tone network\") is a pictorial representation of projected Chroma features onto a 6-dimensional basis representing the perfect fifth, minor third, and major third, revealing affinities and structures between notes and on concrete music pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tonnetz(path):\n",
    "    y, sr = librosa.load(path)\n",
    "    tonnetz = np.array(librosa.feature.tonnetz(y=y, sr=sr))\n",
    "    return tonnetz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Features calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path):\n",
    "\n",
    "    # MFCC feature\n",
    "    mfcc = get_mfcc(path)\n",
    "    mfcc_feature = np.concatenate((mfcc.mean(axis=1), \n",
    "                                   mfcc.min(axis=1), \n",
    "                                   mfcc.max(axis=1)))\n",
    "\n",
    "    # Mel Spectrogram feature\n",
    "    mel_spectrogram = get_mel_spectrogram(path)\n",
    "    mel_spectrogram_feature = np.concatenate((mel_spectrogram.mean(axis=1), \n",
    "                                              mel_spectrogram.min(axis=1), \n",
    "                                              mel_spectrogram.max(axis=1)))\n",
    "\n",
    "    # Chroma Vector feature\n",
    "    chroma_vector = get_chroma_vector(path)\n",
    "    chroma_vector_feature = np.concatenate((chroma_vector.mean(axis=1), \n",
    "                                            chroma_vector.min(axis=1), \n",
    "                                            chroma_vector.max(axis=1)))\n",
    "\n",
    "    # Tonnetz feature\n",
    "    tonnetz = get_tonnetz(path)\n",
    "    tonnetz_feature = np.concatenate((tonnetz.mean(axis=1), \n",
    "                                      tonnetz.min(axis=1), \n",
    "                                      tonnetz.max(axis=1)))\n",
    "\n",
    "    feature = np.concatenate((chroma_vector_feature, mel_spectrogram_feature, mfcc_feature, tonnetz_feature))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features for: blues\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'datasets/gtzan_dataset/genres_original/blues'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m genres:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating features for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m genre \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file\n\u001b[0;32m     13\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(get_features(file_path))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'datasets/gtzan_dataset/genres_original/blues'"
     ]
    }
   ],
   "source": [
    "directory = 'datasets/gtzan_dataset/genres_original'\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
    "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for genre in genres:\n",
    "    print(f\"Calculating features for: {genre}\")\n",
    "    for file in os.listdir(directory + \"/\" + genre):\n",
    "        file_path = directory + \"/\" + genre + \"/\" + file\n",
    "\n",
    "        features.append(get_features(file_path))\n",
    "        labels.append(genres.index(genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = np.random.permutation(999)\n",
    "features = np.array(features)[permutations]\n",
    "labels = np.array(labels)[permutations]\n",
    "\n",
    "features_train = features[0:600]\n",
    "labels_train = labels[0:600]\n",
    "\n",
    "features_val = features[600:799]\n",
    "labels_val = labels[600:799]\n",
    "\n",
    "features_test = features[799:999]\n",
    "labels_test = labels[799:999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow/Keras basic architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(300, activation = 'relu', input_shape=(498,)),\n",
    "        keras.layers.Dense(200, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(),\n",
    "                  loss = 'sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/64\n",
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "19/19 [==============================] - 1s 14ms/step - loss: 101.5077 - accuracy: 0.2133 - val_loss: 41.3180 - val_accuracy: 0.2663\n",
      "Epoch 2/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24.6747 - accuracy: 0.3667 - val_loss: 23.6752 - val_accuracy: 0.3668\n",
      "Epoch 3/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6539 - accuracy: 0.4650 - val_loss: 24.4105 - val_accuracy: 0.2915\n",
      "Epoch 4/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.8572 - accuracy: 0.5633 - val_loss: 19.3386 - val_accuracy: 0.3668\n",
      "Epoch 5/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.1226 - accuracy: 0.6183 - val_loss: 17.1774 - val_accuracy: 0.3668\n",
      "Epoch 6/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.7847 - accuracy: 0.6850 - val_loss: 18.7466 - val_accuracy: 0.3769\n",
      "Epoch 7/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.5263 - accuracy: 0.7500 - val_loss: 14.5663 - val_accuracy: 0.4020\n",
      "Epoch 8/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.8429 - accuracy: 0.8050 - val_loss: 17.3720 - val_accuracy: 0.3819\n",
      "Epoch 9/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.6192 - accuracy: 0.8117 - val_loss: 18.7841 - val_accuracy: 0.3819\n",
      "Epoch 10/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.7428 - accuracy: 0.8133 - val_loss: 18.3557 - val_accuracy: 0.4221\n",
      "Epoch 11/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.4314 - accuracy: 0.8483 - val_loss: 17.0825 - val_accuracy: 0.4171\n",
      "Epoch 12/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.8439 - accuracy: 0.8733 - val_loss: 17.6826 - val_accuracy: 0.4020\n",
      "Epoch 13/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.8717 - val_loss: 15.5633 - val_accuracy: 0.4372\n",
      "Epoch 14/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.9133 - val_loss: 15.3192 - val_accuracy: 0.4121\n",
      "Epoch 15/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.9050 - val_loss: 14.8638 - val_accuracy: 0.4221\n",
      "Epoch 16/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.9300 - val_loss: 15.0205 - val_accuracy: 0.4171\n",
      "Epoch 17/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.9417 - val_loss: 15.8659 - val_accuracy: 0.4523\n",
      "Epoch 18/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.9533 - val_loss: 14.9567 - val_accuracy: 0.4372\n",
      "Epoch 19/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.9350 - val_loss: 16.3537 - val_accuracy: 0.4422\n",
      "Epoch 20/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9567 - val_loss: 17.1929 - val_accuracy: 0.4472\n",
      "Epoch 21/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9450 - val_loss: 15.4254 - val_accuracy: 0.4623\n",
      "Epoch 22/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.9517 - val_loss: 16.0627 - val_accuracy: 0.4774\n",
      "Epoch 23/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.9417 - val_loss: 15.6436 - val_accuracy: 0.4322\n",
      "Epoch 24/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9700 - val_loss: 15.5998 - val_accuracy: 0.4623\n",
      "Epoch 25/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9833 - val_loss: 15.1785 - val_accuracy: 0.4573\n",
      "Epoch 26/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9817 - val_loss: 15.2109 - val_accuracy: 0.4724\n",
      "Epoch 27/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9867 - val_loss: 14.2690 - val_accuracy: 0.4824\n",
      "Epoch 28/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9800 - val_loss: 15.4571 - val_accuracy: 0.4523\n",
      "Epoch 29/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9933 - val_loss: 16.6238 - val_accuracy: 0.4724\n",
      "Epoch 30/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0894 - accuracy: 0.9533 - val_loss: 19.8665 - val_accuracy: 0.4523\n",
      "Epoch 31/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.3431 - accuracy: 0.8950 - val_loss: 17.3065 - val_accuracy: 0.4422\n",
      "Epoch 32/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0448 - accuracy: 0.8750 - val_loss: 16.4346 - val_accuracy: 0.4623\n",
      "Epoch 33/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.9000 - val_loss: 14.6234 - val_accuracy: 0.4623\n",
      "Epoch 34/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.9150 - val_loss: 14.6104 - val_accuracy: 0.4774\n",
      "Epoch 35/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.8967 - val_loss: 14.0983 - val_accuracy: 0.4673\n",
      "Epoch 36/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.9267 - val_loss: 16.0915 - val_accuracy: 0.4523\n",
      "Epoch 37/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9683 - val_loss: 13.6710 - val_accuracy: 0.4623\n",
      "Epoch 38/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9800 - val_loss: 15.4569 - val_accuracy: 0.4573\n",
      "Epoch 39/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9783 - val_loss: 13.8262 - val_accuracy: 0.4774\n",
      "Epoch 40/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9900 - val_loss: 13.7099 - val_accuracy: 0.4824\n",
      "Epoch 41/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9883 - val_loss: 14.1608 - val_accuracy: 0.5226\n",
      "Epoch 42/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9700 - val_loss: 15.8306 - val_accuracy: 0.4925\n",
      "Epoch 43/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9600 - val_loss: 14.3453 - val_accuracy: 0.4724\n",
      "Epoch 44/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9817 - val_loss: 13.6681 - val_accuracy: 0.4724\n",
      "Epoch 45/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9817 - val_loss: 14.5099 - val_accuracy: 0.4975\n",
      "Epoch 46/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9850 - val_loss: 15.0790 - val_accuracy: 0.5025\n",
      "Epoch 47/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9833 - val_loss: 15.6767 - val_accuracy: 0.4623\n",
      "Epoch 48/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9867 - val_loss: 14.5534 - val_accuracy: 0.4673\n",
      "Epoch 49/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 15.7622 - val_accuracy: 0.5176\n",
      "Epoch 50/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 14.1394 - val_accuracy: 0.5075\n",
      "Epoch 51/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9950 - val_loss: 14.6618 - val_accuracy: 0.4975\n",
      "Epoch 52/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9900 - val_loss: 12.3108 - val_accuracy: 0.5025\n",
      "Epoch 53/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 14.0977 - val_accuracy: 0.4824\n",
      "Epoch 54/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 14.0007 - val_accuracy: 0.5276\n",
      "Epoch 55/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 13.8086 - val_accuracy: 0.5025\n",
      "Epoch 56/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 13.5399 - val_accuracy: 0.5126\n",
      "Epoch 57/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.9181e-04 - accuracy: 1.0000 - val_loss: 13.5207 - val_accuracy: 0.5226\n",
      "Epoch 58/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.8808e-04 - accuracy: 1.0000 - val_loss: 13.5230 - val_accuracy: 0.5226\n",
      "Epoch 59/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.3135e-04 - accuracy: 1.0000 - val_loss: 13.5330 - val_accuracy: 0.5327\n",
      "Epoch 60/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.9765e-04 - accuracy: 1.0000 - val_loss: 13.5274 - val_accuracy: 0.5327\n",
      "Epoch 61/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.7495e-04 - accuracy: 1.0000 - val_loss: 13.5220 - val_accuracy: 0.5327\n",
      "Epoch 62/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.5445e-04 - accuracy: 1.0000 - val_loss: 13.5132 - val_accuracy: 0.5276\n",
      "Epoch 63/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.3936e-04 - accuracy: 1.0000 - val_loss: 13.5094 - val_accuracy: 0.5226\n",
      "Epoch 64/64\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.2534e-04 - accuracy: 1.0000 - val_loss: 13.5029 - val_accuracy: 0.5276\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "history = model.fit(x=features_train.tolist(),\n",
    "                    y=labels_train.tolist(),\n",
    "                    verbose=1,\n",
    "                    validation_data=(features_val.tolist(),\n",
    "                                     labels_val.tolist()),\n",
    "                    epochs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               149700    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 211910 (827.77 KB)\n",
      "Trainable params: 211910 (827.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chart for accuracy and loss on both training and validation\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 51.499998569488525%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=features_test.tolist(),y=labels_test.tolist(), verbose=0)\n",
    "print('Accuracy : ' + str(score[1]*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
